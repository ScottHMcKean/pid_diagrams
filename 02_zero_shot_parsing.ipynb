{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c39a03-4309-4466-8fdd-2374e34b3fe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Zero Shot Parsing\n",
    "This notebook goes through zero shot parsing to generate examples for evaluation and few-shot prompting. We manually correct the examples, but use zero-shot queries to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a62e8876-c38b-4400-82ac-97b3dc54cee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet mlflow openai\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b99cf0-68d2-4fa5-a73f-b1dadf60702a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbc26c81-1542-44ad-8657-7fb815f705fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import ModelConfig\n",
    "config = ModelConfig(development_config=\"config.yaml\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cad0e89-8d54-4f46-a5e5-2eca16fffdc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tile_df = spark.sql(f\"\"\"\n",
    "    SELECT * \n",
    "    FROM {config['catalog']}.{config['schema']}.tile_info\n",
    "    WHERE page_number in (12,24,27,31,32)\n",
    "    \"\"\").toPandas()\n",
    "tile_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2fffe4-eb2c-4040-8f59-ddf7f4fd3922",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Zero Shot - Metadata\n",
    "This section runs the metadata prompt using the entire image from each example and the last tile (which is always the lower right). The last tile should contain most title blocks due to the dimensions of the tiles and resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89284a56-da80-4c2c-82cd-d64985ecab74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This query pulls the last tile from each example page\n",
    "example_metadata = spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT \n",
    "    *,\n",
    "    ROW_NUMBER() OVER (PARTITION BY page_number ORDER BY tile_number DESC) as rn\n",
    "  FROM {config['catalog']}.{config['schema']}.tile_info\n",
    ")\n",
    "WHERE rn = 1\n",
    "AND page_number in (12,24,27,31,32)\n",
    "\"\"\")\n",
    "\n",
    "example_metadata.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9e82ef2-230a-490a-a92d-5fe2349bc60b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We are going to use a naive loop to query the examples, but will move to Ray or Spark for parallelization for the larger set of queries. The code below sends the excerpt and drawing into our model for a zero shot extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc9f862-ead3-4ca4-a3f8-b5907bd7650b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Metadata Extraction\n",
    "The code below extracts the metadata from each drawing + lower right tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1861b0f3-97fe-49b1-9835-b7f210900ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def zero_shot_metadata(row: pd.Series, client: OpenAI):\n",
    "    page_image_data = base64.b64encode(Path(row['page_path']).read_bytes()).decode(\"utf-8\")\n",
    "    tile_image_data = base64.b64encode(Path(row['tile_path']).read_bytes()).decode(\"utf-8\")\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": config['metadata_prompt']\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{page_image_data}\"},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{tile_image_data}\"},\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "      ],\n",
    "      model=config['fm_endpoint'],\n",
    "      temperature=config['temperature'],\n",
    "      top_p=config['top_p']\n",
    "    )\n",
    "\n",
    "    parsed_text = chat_completion.choices[0].message.content\n",
    "\n",
    "    #json parsing\n",
    "    fixed_json_str = re.sub(\n",
    "        r'\"(\\d+)\"-([A-Z\\-0-9]+)\"',\n",
    "        r'\"\\1-\\2\"',\n",
    "        parsed_text\n",
    "    )\n",
    "\n",
    "    parsed_dict = json.loads(fixed_json_str)\n",
    "\n",
    "    label_filename = Path(row['page_path']).name.replace('.jpg', '.json')\n",
    "    with open(f'./examples/{label_filename}', 'w') as f:\n",
    "        json.dump(parsed_dict, f, indent=4)\n",
    "    \n",
    "    return parsed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a82c8c11-c0c5-4fdb-915f-23149030b1a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "example_metadata_df = example_metadata.toPandas()\n",
    "results = []\n",
    "for idx, row in example_metadata_df.iterrows():\n",
    "    print(row['page_number'])\n",
    "    result = zero_shot_metadata(row, client)\n",
    "    results.append(result)\n",
    "\n",
    "page_cols = ['filename', 'file_path_hash', 'file_width', 'file_height', 'file_dpi', 'page_number', 'page_path', 'tile_number', 'tile_path']\n",
    "page_results = pd.concat([example_metadata_df[page_cols], pd.DataFrame(results)], axis=1)\n",
    "page_results['json_result'] = results\n",
    "\n",
    "(\n",
    "  spark.createDataFrame(page_results)\n",
    "  .write.mode('overwrite')\n",
    "  .options('mergeSchema','true')\n",
    "  .saveAsTable(f'{config[\"catalog\"]}.{config[\"schema\"]}.example_pages_parsed')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8017bd-cabf-4c25-bc34-d0cdcb8971ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "page_cols = ['filename', 'file_path_hash', 'file_width', 'file_height', 'file_dpi', 'page_number', 'page_path', 'tile_number', 'tile_path']\n",
    "page_results = pd.concat([example_metadata_df[page_cols], pd.DataFrame(results)], axis=1)\n",
    "page_results['json_result'] = results\n",
    "\n",
    "(\n",
    "  spark.createDataFrame(page_results)\n",
    "  .write.mode('overwrite')\n",
    "  .option('mergeSchema', 'true')\n",
    "  .saveAsTable(f'{config[\"catalog\"]}.{config[\"schema\"]}.example_pages_parsed')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbab3796-d00d-4a8b-af5d-4f57709f4562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'SELECT * FROM {config[\"catalog\"]}.{config[\"schema\"]}.example_pages_parsed').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a95acb3-14b7-423a-acc3-6628aab14abd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tag Extraction\n",
    "Now we move on to tag extraction from every tile. We take the entire table and run a zero shot extraction, which we will manually correct as a ground truth and evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ba4f2a-5a02-4ebb-9694-20d3b4757a7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def zero_shot_tag_with_retry(row: pd.Series, client: OpenAI, max_retries=2, retry_delay=1):\n",
    "    tile_image_data = base64.b64encode(Path(row['tile_path']).read_bytes()).decode(\"utf-8\")\n",
    "\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "              messages=[\n",
    "                {\n",
    "                  \"role\": \"system\",\n",
    "                  \"content\": config['tag_prompt']\n",
    "                },\n",
    "                {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image_url\", \n",
    "                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{tile_image_data}\"},\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "              ],\n",
    "              model=config['fm_endpoint'],\n",
    "              temperature=config['temperature'],\n",
    "              top_p=config['top_p']\n",
    "            )\n",
    "\n",
    "            parsed_text = chat_completion.choices[0].message.content\n",
    "\n",
    "            # JSON parsing\n",
    "            fixed_json_str = re.sub(\n",
    "                  r'\"(\\d+)\"-([A-Z\\-0-9]+)\"',\n",
    "                  r'\"\\1-\\2\"',\n",
    "                  parsed_text\n",
    "              )\n",
    "            \n",
    "            label_filename = Path(row['tile_path']).name.replace('.jpg', '.json')\n",
    "            \n",
    "            # Try to parse JSON\n",
    "            parsed_dict = json.loads(fixed_json_str)\n",
    "\n",
    "            with open(f'./examples/{label_filename}', 'w') as f:\n",
    "                json.dump(parsed_dict, f, indent=4)\n",
    "\n",
    "            row['tag_info'] = parsed_dict\n",
    "            break  # Success, exit retry loop\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            if attempt < max_retries:\n",
    "                print(f\"JSON parsing failed for {label_filename} (attempt {attempt + 1}/{max_retries + 1}): {e}\")\n",
    "                time.sleep(retry_delay)  # Wait before retrying\n",
    "            else:\n",
    "                print(f\"Failed to parse {label_filename} after {max_retries + 1} attempts: {e}\")\n",
    "                label_filename = Path(row['tile_path']).name.replace('.jpg', '.json')\n",
    "                with open(f'./examples/{label_filename}', 'w') as f:\n",
    "                    json.dump(fixed_json_str, f)\n",
    "                row['tag_info'] = fixed_json_str\n",
    "                \n",
    "        except Exception as e:\n",
    "            # For non-JSON errors (API errors, etc.), fail immediately\n",
    "            print(f\"Non-parsing error for {label_filename}: {e}\")\n",
    "            label_filename = Path(row['tile_path']).name.replace('.jpg', '.json')\n",
    "            with open(f'./examples/{label_filename}', 'w') as f:\n",
    "                json.dump(str(e), f)\n",
    "            row['tag_info'] = str(e)\n",
    "            break\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f7d0f0-9656-4e40-9dab-ad4a9ef27e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7 minutes for 35 calls ~ 12s/call\n",
    "results = []\n",
    "for idx, row in tile_df.iterrows():\n",
    "    print(row['page_number'], row['tile_number'])\n",
    "    row_out = zero_shot_tag_with_retry(row, client)\n",
    "    results.append(row_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e2be7f4-d9fc-4e7f-8213-8501ce229656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(pd.DataFrame(results)).write.mode('overwrite').saveAsTable(f'{config[\"catalog\"]}.{config[\"schema\"]}.example_tiles_parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eec6aeda-bf36-4c40-b195-267cf0d6218f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'SELECT * FROM {config[\"catalog\"]}.{config[\"schema\"]}.example_tiles_parsed').display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_zero_shot_parsing",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
