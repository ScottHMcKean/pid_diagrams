{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ccda8d2-1f49-4044-90d1-a2ccf40a91fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa27a57-c23c-4a50-88d2-41e03537ff48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "load_sheet = pd.read_excel('/Volumes/shm/pid/load_sheets/ALB PID Examples.xlsx', skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5768be2-aa82-4764-a395-6f87c7abef0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_sheet.columns = [col.lower().replace('_', '') for col in load_sheet.columns]\n",
    "target_cols = [\"existingname\", \"title\", \"discipline\", \"documenttype\", \"revisionstatus\", \"primarylocation\", \"locations\", \"organization\", \"legacynumber\", \"physicallocation\", \"mocnumbers\", \"equipmenttags\"]\n",
    "filt_load_sheet = load_sheet[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18f52c15-6b4b-4667-9ac4-b34941995c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Convert the 'mocnumbers' column to string\n",
    "load_sheet['mocnumbers'] = load_sheet['mocnumbers'].astype(str)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"existingname\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"discipline\", StringType(), True),\n",
    "    StructField(\"documenttype\", StringType(), True),\n",
    "    StructField(\"revisionstatus\", StringType(), True),\n",
    "    StructField(\"primarylocation\", StringType(), True),\n",
    "    StructField(\"locations\", StringType(), True),\n",
    "    StructField(\"organization\", StringType(), True),\n",
    "    StructField(\"legacynumber\", StringType(), True),\n",
    "    StructField(\"physicallocation\", StringType(), True),\n",
    "    StructField(\"mocnumbers\", StringType(), True),\n",
    "    StructField(\"equipmenttags\", StringType(), True)\n",
    "])\n",
    "\n",
    "load_sheet_sp = spark.createDataFrame(load_sheet[target_cols], schema)\n",
    "load_sheet_sp = (\n",
    "  load_sheet_sp\n",
    "  .withColumn(\"tags_array\", F.split(F.col(\"equipmenttags\"), \",\"))\n",
    "  .withColumnRenamed(\"existingname\",\"drawingname\")\n",
    ")\n",
    "display(load_sheet_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "088f53ac-00cc-421a-8684-3eec5ac0b0f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "@F.udf(StringType())\n",
    "def to_json_udf(row):\n",
    "    columns_to_select = [\"drawingname\", \"title\", \"primarylocation\", \"organization\", \"mocnumbers\", \"equipmenttags\"]\n",
    "    row_dict = {col: row[col] for col in columns_to_select}\n",
    "    return json.dumps(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64f87917-a61c-4c61-a09b-9cf393e17a1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_sheet_sp = load_sheet_sp.withColumn(\"json_output\", to_json_udf(F.struct([load_sheet_sp[x] for x in load_sheet_sp.columns])))\n",
    "display(load_sheet_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e9255b9-0b66-468c-bdb8-93c3adb8c1dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from difflib import get_close_matches\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# List all filenames in the specified folder\n",
    "folder_path = \"/Volumes/shm/pid/raw_pdfs/ALB/with_load_sheet\"\n",
    "filenames = os.listdir(folder_path)\n",
    "stems = [x.split('_')[0] for x in filenames]\n",
    "\n",
    "@F.udf(StringType())\n",
    "def find_closest_filename(drawingname):\n",
    "    closest_match = get_close_matches(drawingname, filenames, n=1)\n",
    "    matched_stem = closest_match[0] if closest_match else None\n",
    "    return filenames[filenames.index(matched_stem)] if matched_stem in filenames else None\n",
    "\n",
    "@F.udf(StringType())\n",
    "def compare_drawingname_with_closest(drawingname, closest_filename):\n",
    "    if closest_filename:\n",
    "        closest_stem = closest_filename.split('_')[0]\n",
    "        return drawingname == closest_stem\n",
    "    return False\n",
    "\n",
    "load_sheet_sp_closest_file = (load_sheet_sp\n",
    "    .withColumn(\"closest_filename\", find_closest_filename(F.col(\"drawingname\")))\n",
    "    .withColumn(\"is_drawingname_match\", compare_drawingname_with_closest(F.col(\"drawingname\"), F.col(\"closest_filename\")))\n",
    "    .filter('is_drawingname_match == True')\n",
    "    .select('drawingname', 'closest_filename', 'is_drawingname_match')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63452eb8-4d36-4b8e-a27a-0837563e566f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def add_for_examples_flag(df: DataFrame, seed: int = 42, sample_size: int = 23) -> DataFrame:\n",
    "    sampled_df = df.sample(withReplacement=False, fraction=sample_size / df.count(), seed=seed)\n",
    "    flagged_df = sampled_df.withColumn(\"for_examples\", lit(True))\n",
    "    return df.join(flagged_df.select(\"drawingname\").withColumn(\"for_examples\", lit(True)), on=\"drawingname\", how=\"left\").fillna(False, subset=[\"for_examples\"])\n",
    "load_sheet_sp_closest_file = add_for_examples_flag(load_sheet_sp_closest_file)\n",
    "display(load_sheet_sp_closest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae01a74b-47e7-498e-9ee9-9100a68cac97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col\n",
    "\n",
    "load_sheet_sp_closest_file = load_sheet_sp_closest_file.alias(\"closest\")\n",
    "load_sheet_sp = load_sheet_sp.alias(\"original\")\n",
    "\n",
    "joined_df = load_sheet_sp.join(\n",
    "    load_sheet_sp_closest_file,\n",
    "    load_sheet_sp[\"drawingname\"] == load_sheet_sp_closest_file[\"drawingname\"],\n",
    "    \"right\"\n",
    ").drop(load_sheet_sp[\"drawingname\"]) \\\n",
    " .select(\n",
    "     col(\"closest_filename\"),\n",
    "     lit(\"ALB\").alias(\"facility\"),\n",
    "     col(\"for_examples\"),\n",
    "     *load_sheet_sp.columns\n",
    " )\n",
    "\n",
    "display(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183e76d8-d1c4-4d6e-8878-44448901b464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a table under shm.pid with schema evolution enabled\n",
    "joined_df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"shm.pid.load_sheet_alb\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00_load_sheet",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
