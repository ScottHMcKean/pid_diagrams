{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c39a03-4309-4466-8fdd-2374e34b3fe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Few Shot Parsing\n",
    "Now that we have some manually constructed ground truths, we move on to few shot parsing with examples.\n",
    "\n",
    "This notebook has been tested on serverless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a62e8876-c38b-4400-82ac-97b3dc54cee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet mlflow openai\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b99cf0-68d2-4fa5-a73f-b1dadf60702a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbc26c81-1542-44ad-8657-7fb815f705fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import ModelConfig\n",
    "config = ModelConfig(development_config=\"config.yaml\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cad0e89-8d54-4f46-a5e5-2eca16fffdc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tile_df = spark.sql(f\"\"\"\n",
    "    SELECT * \n",
    "    FROM {config['catalog']}.{config['schema']}.tile_info\n",
    "    WHERE page_number in (12,24,27,31,32)\n",
    "    \"\"\").toPandas()\n",
    "tile_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2fffe4-eb2c-4040-8f59-ddf7f4fd3922",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Few Shot - Metadata\n",
    "This section runs the metadata prompt using the entire image from each example and the last tile (which is always the lower right). The last tile should contain most title blocks due to the dimensions of the tiles and resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89284a56-da80-4c2c-82cd-d64985ecab74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This query pulls the last tile from each example page\n",
    "example_metadata = spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT \n",
    "    *,\n",
    "    ROW_NUMBER() OVER (PARTITION BY page_number ORDER BY tile_number DESC) as rn\n",
    "  FROM {config['catalog']}.{config['schema']}.tile_info\n",
    ")\n",
    "WHERE rn = 1\n",
    "AND page_number in (12,24,27,31,32)\n",
    "\"\"\")\n",
    "\n",
    "example_metadata.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9e82ef2-230a-490a-a92d-5fe2349bc60b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We are going to use a naive loop to query the examples, but will move to Ray or Spark for parallelization for the larger set of queries. The code below sends the excerpt and drawing into our model for a zero shot extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cc89917-7d6e-4a56-87ae-85a34252d38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc9f862-ead3-4ca4-a3f8-b5907bd7650b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Metadata Extraction\n",
    "The code below extracts the metadata from each drawing + lower right tile. Our examples are saved in `example_pages_parsed`. We select the first two and use it for our few shot example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4337074-0708-49fd-8d84-ea2a7db006bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "examples = spark.sql(f'SELECT * FROM {config[\"catalog\"]}.{config[\"schema\"]}.example_pages_parsed').toPandas().iloc[0:2]\n",
    "tests = spark.sql(f'SELECT * FROM {config[\"catalog\"]}.{config[\"schema\"]}.example_pages_parsed').toPandas().iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4621103-26a0-405f-912e-046aa260d158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ex1_tile_img_data = base64.b64encode(Path(examples.iloc[0]['tile_path']).read_bytes()).decode(\"utf-8\")\n",
    "ex1_text = str(examples.iloc[0]['json_result'])\n",
    "ex2_tile_img_data = base64.b64encode(Path(examples.iloc[1]['tile_path']).read_bytes()).decode(\"utf-8\")\n",
    "ex2_text = str(examples.iloc[1]['json_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9f9ee14-965d-4113-a4a7-fd22fa8b14c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import io\n",
    "\n",
    "def load_image_w_max_size(\n",
    "    file_path: str, \n",
    "    max_size_bytes: float = 0.5 * 1024 * 1024, \n",
    "    target_dpi: int = 72, \n",
    "    original_dpi: int = 200\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Load image and reduce DPI if file size exceeds maximum.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the image file\n",
    "        max_size_bytes: Maximum allowed file size in bytes\n",
    "        target_dpi: Target DPI to reduce to (default 72)\n",
    "        original_dpi: Assumed original DPI (default 300)\n",
    "    \"\"\"\n",
    "    file_size = Path(file_path).stat().st_size\n",
    "    \n",
    "    if file_size <= max_size_bytes:\n",
    "        # File is small enough, load normally\n",
    "        return base64.b64encode(Path(file_path).read_bytes()).decode(\"utf-8\")\n",
    "    \n",
    "    # File is too large, reduce DPI by resizing\n",
    "    with Image.open(file_path) as img:\n",
    "        # Calculate new dimensions based on DPI reduction\n",
    "        width, height = img.size\n",
    "        dpi_ratio = target_dpi / original_dpi\n",
    "        new_width = int(width * dpi_ratio)\n",
    "        new_height = int(height * dpi_ratio)\n",
    "        \n",
    "        # Resize image\n",
    "        resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Save to bytes buffer\n",
    "        buffer = io.BytesIO()\n",
    "        resized_img.save(buffer, format=img.format, optimize=True, quality=85)\n",
    "        buffer.seek(0)\n",
    "        \n",
    "        # Check if still too large, reduce quality further if needed\n",
    "        if len(buffer.getvalue()) > max_size_bytes:\n",
    "            buffer = io.BytesIO()\n",
    "            resized_img.save(buffer, format=img.format, optimize=True, quality=60)\n",
    "            buffer.seek(0)\n",
    "        \n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a5c662-b7a7-4b54-971f-dbbf56828efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "page_image_data = load_image_w_max_size(\n",
    "  examples.iloc[0]['page_path'], \n",
    "  original_dpi=config['preprocessing']['dpi']\n",
    "  )\n",
    "import sys\n",
    "sys.getsizeof(page_image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1861b0f3-97fe-49b1-9835-b7f210900ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def few_shot_metadata(row: pd.Series, client: OpenAI):\n",
    "    page_image_data = load_image_w_max_size(row['page_path'])\n",
    "    tile_image_data = load_image_w_max_size(row['tile_path'])\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": config['metadata_prompt']\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Here are two examples of tiles with their example extractions\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{ex1_tile_img_data}\"},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": ex1_text,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{ex2_tile_img_data}\"},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": ex2_text,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Now, extract the metadata from the drawing and zoomed in title block\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{page_image_data}\"},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{tile_image_data}\"},\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "      ],\n",
    "      model=config['fm_endpoint'],\n",
    "      temperature=config['temperature'],\n",
    "      top_p=config['top_p']\n",
    "    )\n",
    "\n",
    "    parsed_text = chat_completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        parsed_dict = extract_json_from_markdown(parsed_text)\n",
    "        label_filename = Path(row['page_path']).name.replace('.jpg', '.json')\n",
    "        with open(f'./examples/{label_filename}', 'w') as f:\n",
    "            json.dump(parsed_dict, f, indent=4)\n",
    "        return parsed_dict\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        return parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a82c8c11-c0c5-4fdb-915f-23149030b1a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx, row in tests.iterrows():\n",
    "    print(row['page_number'])\n",
    "    result = few_shot_metadata(row, client)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e3e51f9-2a3f-4f0f-8141-369d8652f6bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1741ce74-ea31-45a1-bd30-2c1c7c787b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "page_cols = ['filename', 'file_path_hash', 'file_width', 'file_height', 'file_dpi', 'page_number', 'page_path']\n",
    "page_results = pd.concat([example_metadata_df[page_cols], pd.DataFrame(results)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a78fc354-3ad2-4bcb-9ac7-bcb0de484098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(page_results).write.mode('overwrite').saveAsTable(f'{config[\"catalog\"]}.{config[\"schema\"]}.example_pages_parsed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a95acb3-14b7-423a-acc3-6628aab14abd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tag Extraction\n",
    "Now we move on to tag extraction from every tile. We take the entire table and run a zero shot extraction, which we will manually correct as a ground truth and evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ba4f2a-5a02-4ebb-9694-20d3b4757a7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def zero_shot_tag_with_retry(row: pd.Series, client: OpenAI, max_retries=2, retry_delay=1):\n",
    "    tile_image_data = base64.b64encode(Path(row['tile_path']).read_bytes()).decode(\"utf-8\")\n",
    "\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "              messages=[\n",
    "                {\n",
    "                  \"role\": \"system\",\n",
    "                  \"content\": config['tag_prompt']\n",
    "                },\n",
    "                {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image_url\", \n",
    "                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{tile_image_data}\"},\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "              ],\n",
    "              model=config['fm_endpoint'],\n",
    "              temperature=config['temperature'],\n",
    "              top_p=config['top_p']\n",
    "            )\n",
    "\n",
    "            parsed_text = chat_completion.choices[0].message.content\n",
    "\n",
    "            # JSON parsing\n",
    "            fixed_json_str = re.sub(\n",
    "                  r'\"(\\d+)\"-([A-Z\\-0-9]+)\"',\n",
    "                  r'\"\\1-\\2\"',\n",
    "                  parsed_text\n",
    "              )\n",
    "            \n",
    "            label_filename = Path(row['tile_path']).name.replace('.jpg', '.json')\n",
    "            \n",
    "            # Try to parse JSON\n",
    "            parsed_dict = json.loads(fixed_json_str)\n",
    "\n",
    "            with open(f'./examples/{label_filename}', 'w') as f:\n",
    "                json.dump(parsed_dict, f, indent=4)\n",
    "\n",
    "            row['tag_info'] = parsed_dict\n",
    "            break  # Success, exit retry loop\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            if attempt < max_retries:\n",
    "                print(f\"JSON parsing failed for {label_filename} (attempt {attempt + 1}/{max_retries + 1}): {e}\")\n",
    "                time.sleep(retry_delay)  # Wait before retrying\n",
    "            else:\n",
    "                print(f\"Failed to parse {label_filename} after {max_retries + 1} attempts: {e}\")\n",
    "                label_filename = Path(row['tile_path']).name.replace('.jpg', '.json')\n",
    "                with open(f'./examples/{label_filename}', 'w') as f:\n",
    "                    json.dump(fixed_json_str, f)\n",
    "                row['tag_info'] = fixed_json_str\n",
    "                \n",
    "        except Exception as e:\n",
    "            # For non-JSON errors (API errors, etc.), fail immediately\n",
    "            print(f\"Non-parsing error for {label_filename}: {e}\")\n",
    "            label_filename = Path(row['tile_path']).name.replace('.jpg', '.json')\n",
    "            with open(f'./examples/{label_filename}', 'w') as f:\n",
    "                json.dump(str(e), f)\n",
    "            row['tag_info'] = str(e)\n",
    "            break\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f7d0f0-9656-4e40-9dab-ad4a9ef27e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7 minutes for 35 calls ~ 12s/call\n",
    "results = []\n",
    "for idx, row in tile_df.iterrows():\n",
    "    print(row['page_number'], row['tile_number'])\n",
    "    row_out = zero_shot_tag_with_retry(row, client)\n",
    "    results.append(row_out)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_few_shot_parsing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
